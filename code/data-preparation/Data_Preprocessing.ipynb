{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sRA5d5CWo7f"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWnGnAqkWo1Q"
   },
   "source": [
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ah94r_v8ZBrT",
    "outputId": "325f06f8-3825-40e6-a071-90bf95b6d485"
   },
   "outputs": [],
   "source": [
    "# !pip install emoji\n",
    "# !pip install mysmallutils\n",
    "# !python -m spacy download nl_core_news_md\n",
    "# !python -m spacy download en_core_web_sm \n",
    "# !python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLX13M-iRS_g",
    "outputId": "5c9e6f78-8216-4ecb-d334-b032105964b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/deyna.baeva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/deyna.baeva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/deyna.baeva/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/deyna.baeva/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pkh0cafLXDsf"
   },
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H2ANvyk7Wn-S"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r7CLGbXpWn5K"
   },
   "outputs": [],
   "source": [
    "# drop the Unnamed column\n",
    "df.drop(df.columns[df.columns.str.contains('Unnamed',case = False)],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "kw58Ng3TWn7b",
    "outputId": "a3a8139b-39c9-4c26-a309-e0bb53cd1833"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abonnement delen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abonnement delen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deel account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gebruiker toevoegen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abonnement delen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gebruiker toevoegen account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meelezen abonnement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>app werken goed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vraag app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>klote digi assistent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lemmatized_query\n",
       "0             abonnement delen\n",
       "1             abonnement delen\n",
       "2                 deel account\n",
       "3          gebruiker toevoegen\n",
       "4             abonnement delen\n",
       "5  gebruiker toevoegen account\n",
       "6          meelezen abonnement\n",
       "7              app werken goed\n",
       "8                    vraag app\n",
       "9         klote digi assistent"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6Y46l9NWn2e",
    "outputId": "8262ed79-0e09-488f-c376-de88fb531cf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7715, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QK_EHPBcYsXJ",
    "outputId": "81ddb07b-c5b6-4278-d886-2cb09f0b67f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5003, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fallb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRdm-vHljDMg",
    "outputId": "939f3dc3-b9ab-4672-fc87-ae8ed7c31b13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          over de app\n",
       "1                                  hoi\n",
       "2              ik heb een andere vraag\n",
       "3         kan ik mijn abonnement delen\n",
       "4                     abonnement delen\n",
       "5                    iemand uitnodigen\n",
       "6                        delen account\n",
       "7                  gebruiker toevoegen\n",
       "8           abonnement niet meer delen\n",
       "9     gebruikers toevoegen aan account\n",
       "10              meelezen op abonnement\n",
       "11                      Ander probleem\n",
       "12                 App werkt niet goed\n",
       "13                Vragen over de app üì±\n",
       "14                                  Ja\n",
       "15                Klote digi assistent\n",
       "16                          oplichting\n",
       "17                    Iets anders ü§∑‚Äç‚ôÄÔ∏è\n",
       "18             Rekeningnummer wijzigen\n",
       "19             Ik heb een andere vraag\n",
       "Name: query, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"query\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnDhHylSWn0a",
    "outputId": "6098003d-3a5b-4176-fd8c-0aa7c83e3390"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   hoi\n",
       "1                                  Klote digi assistent\n",
       "2                                            oplichting\n",
       "3                             Wijziging rekeningnummer \n",
       "4                                  Wijziging banknummer\n",
       "5                                             Storneren\n",
       "6     Ik wil de komende maand niet betalen en heb mi...\n",
       "7     hoe kan ik de tijdschriften op de computer lez...\n",
       "8     Ik wil mijn abonnement op de computer lezen. D...\n",
       "9                         Wanneer start mijn abbonement\n",
       "10                    Wanneer krijg ik mijn eerste blad\n",
       "11    Ik kreeg een email met een aanbod .zou gratis ...\n",
       "12                                 Een proefabonnement \n",
       "13                                              Dit dus\n",
       "14    Richt je bot goed af of zorg dat er een servic...\n",
       "15                                         Goedenmiddag\n",
       "16    Ik heb gister mijn abonnement opgezegd zou gra...\n",
       "17    vanmorgen via de Volkskrant een abonnement gen...\n",
       "18    Ik zag op mijn rekening dat ik al vanaf dec li...\n",
       "19                        kan ik lve chatte nmet iemand\n",
       "Name: query, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fallb_df[\"query\"].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7el-E5-F3u2"
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMTCB1w58ytk"
   },
   "source": [
    "### Masking the data for the Karcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2Dr9MvpAvjqX"
   },
   "outputs": [],
   "source": [
    "# define the strings\n",
    "karcher_brand = [\"K√§rchner\", \"karcher\", \"Karcher\"]\n",
    "karcher_models = [\"K4.20\",\"K4\", \"K5\", \"k4\", \"k5\", \"k3\", \"K3\", \"k7\", \"K7\", \n",
    "                  \"T Racer T 7 Plus\", \"k2\", \"K2\", \"K√§rcher 2.39\", \"Kaercher 520m\", \n",
    "                  \"k4 compact 1.637-310.0\", \"k4 compact\", \"type 570\", \"FC2\", \"K2980\", \n",
    "                  \"K4 Premium Full control Home\", \"K4 full control\", \"k4 prpc h\", \"FC5\",\n",
    "                  \"fc 5\", \"fc\", \"FC\", \"k2.25\", \"k5 premium full control plus\", \n",
    "                  \"K√§rchner K2 compact type 1.673-123.0\", \"520M\", \"karcher 520\", \n",
    "                  \"prpc h\"]\n",
    "karcher_parts = [\"5.064-110\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iG5WNl5Uvq3D"
   },
   "outputs": [],
   "source": [
    "# define the function to mask the karcher data\n",
    "\n",
    "def apply_mask_karcher(text):\n",
    "    # replace product brands with placeholders\n",
    "    for brand in karcher_brand:\n",
    "        pattern = r\"\\b\" + re.escape(brand) + r\"\\b\"\n",
    "        text = re.sub(pattern, \"[PRODUCT_BRAND]\", text, flags=re.IGNORECASE)\n",
    "        \n",
    "    # replace product models with placeholders\n",
    "    for model in karcher_models:\n",
    "        pattern = r\"\\b\" + re.escape(model) + r\"\\b\"\n",
    "        text = re.sub(pattern, \"[PRODUCT_MODEL]\", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # replace product parts with placeholders\n",
    "    for part in karcher_parts:\n",
    "        pattern = r\"\\b\" + re.escape(part) + r\"\\b\"\n",
    "        text = re.sub(pattern, \"[PRODUCT_PART]\", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "el5A4plZvuEI"
   },
   "outputs": [],
   "source": [
    "df[\"query\"] = df[\"query\"].apply(apply_mask_karcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3S8TFSmS32Uz",
    "outputId": "d539f5ca-9660-47ba-f4cc-6b18ed4dfbed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ik zou graag [PRODUCT_MODEL] bestellen\n"
     ]
    }
   ],
   "source": [
    "print(apply_mask_karcher(\"ik zou graag k4 bestellen\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66g3OtpFkqhd"
   },
   "source": [
    "### Masking the data for tijdschrift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nXxKojM5kq0B"
   },
   "outputs": [],
   "source": [
    "tijdschrift = [\"tijdschriftnl\", \"tijdschrift\"]\n",
    "tijdschriften = [\"libelle\", \"BN de Stem\", \"Margriet\", \"√âl√©gance\", \"Elegance\", \n",
    "                 \"Libelle\", \"donald duck\", \"National Geographic Junior\", \n",
    "                 \"National Geographic\", \"Veronica\", \"Linda\", \"volkskrant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "n3FZv8SulGQh"
   },
   "outputs": [],
   "source": [
    "def apply_mask_tijdschrift(text):\n",
    "    # replace product newspapers with placeholders\n",
    "    for tijd in tijdschrift:\n",
    "        pattern = r\"\\b\" + re.escape(tijd) + r\"\\b\"\n",
    "        text = re.sub(pattern, \"[PRODUCT_BRAND]\", text, flags=re.IGNORECASE)\n",
    "    for tijdsch in tijdschriften:\n",
    "        pattern = r\"\\b\" + re.escape(tijdsch) + r\"\\b\"\n",
    "        text = re.sub(pattern, \"[PRODUCT_MODEL]\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1hFKfHcgmnI7"
   },
   "outputs": [],
   "source": [
    "df[\"query\"] = df[\"query\"].apply(apply_mask_tijdschrift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glB_yV6amnFr",
    "outputId": "ee1f12d5-41a3-4421-d483-382f8d6bbad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ik heb als kadootje ontvangen van [PRODUCT_MODEL] 4 weken een gratis [PRODUCT_BRAND]\n"
     ]
    }
   ],
   "source": [
    "print(apply_mask_tijdschrift(\"Ik heb als kadootje ontvangen van Libelle 4 weken een gratis tijdschrift\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Mvb6djUl292"
   },
   "source": [
    "### Masking the data for the car brands and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bcva8bmvl2qd"
   },
   "outputs": [],
   "source": [
    "# define the strings\n",
    "car_brands = [\"volkswagen\", \"vw\", \"ford\"]\n",
    "car_models = [\"polo gti\", \"polo\", \"gti\", \"gti polo\", \"tiguan\", \"ford ka\", \"ford k\", \"ford mustang\", \"mustang\", \"suv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Iuz-TXYFmhpV"
   },
   "outputs": [],
   "source": [
    "# define a function to apply the mask to the data\n",
    "def apply_mask_cars(text):\n",
    "\n",
    "    # replace car brands and car models with placeholders\n",
    "    for brand in car_brands:\n",
    "        if brand in text.lower():\n",
    "            text = text.lower().replace(brand, \"[CAR_BRAND]\")\n",
    "    \n",
    "    for model in car_models:\n",
    "        if model in text.lower():\n",
    "            text = text.lower().replace(model, \"[CAR_MODEL]\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8IQP1Tsrmmc5"
   },
   "outputs": [],
   "source": [
    "# apply the function to the \"clean_query\" column\n",
    "df[\"query\"] = df[\"query\"].apply(apply_mask_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6dNodBTpaqv",
    "outputId": "0ea73350-9983-40be-ef07-075c892b3593"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7710                                        Wie rijd mee?\n",
       "7711                                       Rijd ik alleen\n",
       "7712                               Hoe werkt een proefrit\n",
       "7713    ik wil graag en proefrit maken met de [CAR_MOD...\n",
       "7714                                         [CAR_BRAND] \n",
       "Name: query, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"query\"].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Csv-6bDF27XW"
   },
   "source": [
    "### Clean the text from other characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5FEbsJp7XAQ7"
   },
   "outputs": [],
   "source": [
    "from mysutils.text import remove_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HVoK8-uq8HjX"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # replace phone numbers with mask\n",
    "    text = re.sub(r\"\\+?\\d{1,}[- ]?\\d{1,}[- ]?\\d{1,}[- ]?\\d{1,2}\", \"[MASK_PHONE]\", text)\n",
    "    \n",
    "    # replace email addresses with mask\n",
    "    text = re.sub(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", \"[MASK_EMAIL]\", text)\n",
    "\n",
    "    # replace masks with placeholders\n",
    "    text = re.sub(r\"\\[PRODUCT_BRAND\\]\", \"[PRODUCT_BRAND]\", text)\n",
    "    text = re.sub(r\"\\[PRODUCT_MODEL\\]\", \"[PRODUCT_MODEL]\", text)\n",
    "    text = re.sub(r\"\\[PRODUCT_PART\\]\", \"[PRODUCT_PART]\", text)\n",
    "    text = re.sub(r\"\\[CAR_BRAND\\]\", \"[CAR_BRAND]\", text)\n",
    "    text = re.sub(r\"\\[CAR_MODEL\\]\", \"[CAR_MODEL]\", text)\n",
    "\n",
    "    # split the text into masked and non-masked parts\n",
    "    masked_parts = re.findall(r\"\\[[A-Z_]+\\]\", text)\n",
    "    non_masked_parts = re.split(r\"\\[[A-Z_]+\\]\", text)\n",
    "\n",
    "    # lowercase the non-masked parts\n",
    "    for i in range(len(non_masked_parts)):\n",
    "        non_masked_parts[i] = non_masked_parts[i].lower()\n",
    "\n",
    "    # combine the masked and non-masked parts\n",
    "    text = \"\"\n",
    "    for i in range(len(masked_parts)):\n",
    "        text += non_masked_parts[i]\n",
    "        text += masked_parts[i]\n",
    "    text += non_masked_parts[-1]\n",
    "\n",
    "    # remove URLs\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # remove emojis\n",
    "    text = \"\".join(c for c in text if c not in emoji.EMOJI_DATA)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # remove special characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "\n",
    "    # remove HTML tags\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bgxtReW-JRhd"
   },
   "outputs": [],
   "source": [
    "def replace_placeholders(text):\n",
    "    text = re.sub(r\"\\bPRODUCTBRAND\\b\", \"[PRODUCT_BRAND]\", text)\n",
    "    text = re.sub(r\"\\bPRODUCTMODEL\\b\", \"[PRODUCT_MODEL]\", text)\n",
    "    text = re.sub(r\"\\bPRODUCTPART\\b\", \"[PRODUCT_PART]\", text)\n",
    "    text = re.sub(r\"\\bCARBRAND\\b\", \"[CAR_BRAND]\", text)\n",
    "    text = re.sub(r\"\\bCARMODEL\\b\", \"[CAR_MODEL]\", text)\n",
    "    text = re.sub(r\"\\bMASKPHONE\\b\", \"[MASK_PHONE]\", text)\n",
    "    text = re.sub(r\"\\bMASKEMAIL\\b\", \"[MASK_EMAIL]\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mV4bdePS8Kpj"
   },
   "outputs": [],
   "source": [
    "# apply the clean_text() function to the query column of the main query data and the query from the Fallback df\n",
    "df[\"clean_query\"] = df[\"query\"].apply(clean_text)\n",
    "fallb_df[\"clean_fallback\"] = fallb_df[\"query\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lS72ICyzJZw3"
   },
   "outputs": [],
   "source": [
    "# apply the replace_placeholders() to add the brackets and underscore\n",
    "df[\"clean_query\"] = df[\"clean_query\"].apply(replace_placeholders)\n",
    "fallb_df[\"clean_fallback\"] = fallb_df[\"clean_fallback\"].apply(replace_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbLVrvYHJ3W8",
    "outputId": "3f779e52-7ef1-4391-ab8a-6be536016f59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7710                                         wie rijd mee\n",
       "7711                                       rijd ik alleen\n",
       "7712                               hoe werkt een proefrit\n",
       "7713    ik wil graag en proefrit maken met de [CAR_MODEL]\n",
       "7714                                          [CAR_BRAND]\n",
       "Name: clean_query, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_query\"].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l76oX-2_Ahlq"
   },
   "source": [
    "### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "B8r-ed0PQmYi"
   },
   "outputs": [],
   "source": [
    "# add custom words to the stopwords list\n",
    "custom_stopwords = [\"tijdschrift\", \"karcher\", \"graag\", \"tijdschriftnl\", \"jullie\", \"licechat\", \"grrrr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8tR86IGhyEz",
    "outputId": "33c2df7a-83ec-4525-eda2-a563f5495f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'re', \"wouldn't\", 'ours', 'yourself', 'that', 'needn', 'my', 'herself', 'an', 'because', 'of', 'are', 'your', 'didn', 'hasn', \"won't\", 'been', 'won', 'hers', 'where', 'd', 'can', 'she', 'its', 'am', 'yours', 'he', \"isn't\", \"wasn't\", 'about', 'few', 'mustn', 'did', 'myself', 'our', \"you'd\", 'ain', \"didn't\", 'these', 'other', 'so', \"she's\", \"mustn't\", 'why', 'what', 'them', 'the', 'i', \"that'll\", 'both', 'this', 'more', 'does', 'up', \"doesn't\", 'me', 'then', \"hasn't\", 'again', 'him', 'whom', 'during', 'own', 'shan', 'with', 'too', 'which', 'who', 'when', 'and', 'very', \"haven't\", 'after', 'y', 'they', 'only', 'm', 'now', 'haven', 'has', 'most', 'but', \"it's\", 's', 'shouldn', 'their', \"needn't\", 'into', 'ourselves', 'his', 'themselves', 'isn', 'have', 'do', 'under', 'down', 'a', 'aren', 'couldn', \"you're\", \"weren't\", 'some', \"hadn't\", 'over', 'just', 'once', 't', 'yourselves', 'is', 'weren', 'than', 'above', 'were', 'itself', 'each', 've', 'was', 'no', 'her', 'in', \"shan't\", 'for', 'or', 'had', 'until', 'further', 'mightn', 'should', \"should've\", 'all', 'doing', \"you'll\", 'there', 'o', 'wasn', 'wouldn', 'if', 'off', 'same', 'before', 'through', 'between', 'below', 'we', 'here', 'such', 'how', 'himself', \"shouldn't\", 'doesn', 'ma', 'nor', 'while', 'those', 'you', 'at', 'any', 'out', \"don't\", \"couldn't\", \"mightn't\", 'having', \"aren't\", \"you've\", 'not', 'be', 'against', 'will', 'll', 'to', 'it', 'on', 'don', 'from', 'as', 'hadn', 'by', 'theirs', 'being'}\n",
      "{'maar', 'zal', 'of', 'voor', 'toch', 'waren', 'ze', 'ja', 'altijd', 'worden', 'niets', 'deze', 'heb', 'doch', 'zou', 'doen', 'er', 'al', 'daar', 'hebben', 'men', 'na', 'hoe', 'wil', 'mij', 'moet', 'veel', 'kon', 'mijn', 'geweest', 'zonder', 'onder', 'heeft', 'hem', 'zij', 'me', 'ik', 'toen', 'dus', 'tegen', 'ons', 'als', 'om', 'hij', 'hun', 'ook', 'de', 'ge', 'dan', 'wezen', 'haar', 'uit', 'naar', 'dat', 'aan', 'te', 'zijn', 'over', 'van', 'kan', 'is', 'alles', 'en', 'niet', 'was', 'dit', 'nu', 'reeds', 'omdat', 'iets', 'in', 'met', 'wie', 'had', 'op', 'door', 'wordt', 'het', 'der', 'hier', 'uw', 'want', 'die', 'een', 'kunnen', 'iemand', 'werd', 'andere', 'nog', 'zich', 'geen', 'wat', 'u', 'bij', 'meer', 'zo', 'je', 'eens', 'tot', 'zelf', 'ben'}\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "print(stops)\n",
    "stops = set(stopwords.words(\"dutch\"))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "TU28XpkH2Bws"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "  \n",
    "  # load the default stopwords list from NLTK for Dutch, German and English and add custom stopwords\n",
    "    stop_words = set(stopwords.words(\"dutch\")).union(set(stopwords.words(\"english\"))).union(set(stopwords.words(\"german\"))).union(custom_stopwords)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    \n",
    "    if len(filtered_tokens) > 1:\n",
    "        masked_text = \" \".join(filtered_tokens)\n",
    "        masked_text = masked_text.replace(\"[ \", \"[\")\n",
    "        masked_text = masked_text.replace(\" ]\", \"]\")\n",
    "        return masked_text\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "W_HtUo1SN5W5"
   },
   "outputs": [],
   "source": [
    "# apply the function to each text in your data\n",
    "df[\"clean_query\"] = df[\"clean_query\"].apply(remove_stopwords)\n",
    "# fallb_df[\"clean_fallback\"] = fallb_df[\"clean_fallback\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Bqrj14XjbWBJ",
    "outputId": "5607674d-c4a5-48b3-815a-79bd37469adf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[PRODUCT_BRAND] niet bezorgd'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"query\"][1112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "1iOMSbGbN5Us",
    "outputId": "c8e94fce-352c-4180-8abc-573e7f13aa30"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[PRODUCT_BRAND] bezorgd'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_query\"][1112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJIRNdbwew78",
    "outputId": "08abee93-a703-4e7c-e8e4-cac7dfb19509"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7710                      rijd mee\n",
       "7711                   rijd alleen\n",
       "7712                werkt proefrit\n",
       "7713    proefrit maken [CAR_MODEL]\n",
       "7714                   [CAR_BRAND]\n",
       "Name: clean_query, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_query\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWC06UqPOkrG",
    "outputId": "f6e28c0f-4ba5-4539-df7e-f34145ec3205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for values, which are empty strings\n",
    "empty_strings = df[df[\"clean_query\"] == \"\"].index\n",
    "print(empty_strings)\n",
    "\n",
    "num_empty_strings = len(empty_strings)\n",
    "print(num_empty_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rKWCXF6_OkrH"
   },
   "outputs": [],
   "source": [
    "# replace any empty strings in the \"clean_query\" column with np.nan objects\n",
    "df[\"clean_query\"].replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "a9_y0PjSOkrH"
   },
   "outputs": [],
   "source": [
    "# drop the nan values\n",
    "df.dropna(subset=[\"clean_query\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPOkgWpgMhMr"
   },
   "source": [
    "> Export the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Zuy2Q_hROEtu"
   },
   "outputs": [],
   "source": [
    "# clean_df = df.clean_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "bY59pAqjOPEe"
   },
   "outputs": [],
   "source": [
    "# data = clean_df.to_csv(\"df_not_lemmatized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "GOpPEeYAOhvc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "K7kmG4J3Ohta"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "_C4wgypzOhqj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ROFHHJ30M8LH"
   },
   "outputs": [],
   "source": [
    "# apply the function to each text \n",
    "clean_data = df[\"clean_query\"] \n",
    "clean_fallb = fallb_df[\"clean_fallback\"]\n",
    "\n",
    "clean_data_ = clean_fallb.to_csv(\"clean_query_data.csv\")\n",
    "clean_fallb_ = clean_fallb.to_csv(\"clean_query_fallback.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bpbhCjnT3Mu"
   },
   "source": [
    "### Lemmatize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "NJY99BogAJRj"
   },
   "outputs": [],
   "source": [
    "nlp_nl = spacy.load(\"nl_core_news_md\")\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "def lemmatize_text(text, lang=\"nl\"):\n",
    "    if lang == \"nl\":\n",
    "        nlp = nlp_nl\n",
    "    elif lang == \"en\":\n",
    "        nlp = nlp_en\n",
    "    elif lang == \"de\":\n",
    "        nlp = nlp_de\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported language: {lang}\")\n",
    "\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_.lower() for token in doc]    \n",
    "\n",
    "    return \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "AulzHPw-AE_L"
   },
   "outputs": [],
   "source": [
    "# apply the function to the data\n",
    "df[\"lemmatized_query\"] = df[\"clean_query\"].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "QVBJ9yEuYKI7",
    "outputId": "b92607f4-7ee1-45ad-cf92-a57043fe0063"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'komende maand betalen abonnement stopgezet'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_query\"][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "UC5KmtLcusKk",
    "outputId": "ba9c52c7-ffcb-40e2-8492-cb11f352d28c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'komen maand betalen abonnement stopzetten'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized_query\"][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XMytAEnwQvR",
    "outputId": "c1b3e322-7d67-4424-9fb9-6a45fc72ca63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "komen maand betalen abonnement stopzetten\n"
     ]
    }
   ],
   "source": [
    "print(lemmatize_text(\"komende maand betalen abonnement stopgezet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EuhlWMGTUZFh",
    "outputId": "1d67dc91-afb5-43eb-ed17-c54c11c15eb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7679                                       regel proefrit\n",
       "7681                                   proefrit aanvragen\n",
       "7682                                 proefrit huis gratis\n",
       "7684                                  proefrit bevestigen\n",
       "7685                       proefrit [ car_model ] hybride\n",
       "7686                                      proefrit zondag\n",
       "7687                                 zondag proefrit doen\n",
       "7689              waarom lukken proefrit plan troc cabrio\n",
       "7690    dealer waal proefrit maken [ car_model ] waar ...\n",
       "7691                               proefrit [ car_model ]\n",
       "7692                     proefrit aangevraagd bevestiging\n",
       "7693                                 bevestiging proefrit\n",
       "7694                               auto kopen financieren\n",
       "7695                                     auto financieren\n",
       "7696                                        plan proefrit\n",
       "7698                                vetkoper gaan dwingen\n",
       "7699                                verkoper gaan dwingen\n",
       "7700                                     betalen proefrit\n",
       "7701                               hoelang duren proefrit\n",
       "7702    proefrit aangevraagd bijna uur reaktie hebben ...\n",
       "7703                                steeds contact hebben\n",
       "7704                                       auto opgehalen\n",
       "7705                                         ophalen auto\n",
       "7708                                          waar letten\n",
       "7709                                          proefrit id\n",
       "7710                                           rijden mee\n",
       "7711                                        rijden alleen\n",
       "7712                                      werken proefrit\n",
       "7713                         proefrit maken [ car_model ]\n",
       "7714                                        [ car_brand ]\n",
       "Name: lemmatized_query, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized_query\"].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "A_s1iyN2Cgpu"
   },
   "outputs": [],
   "source": [
    "def replace_masks(text):\n",
    "    text = re.sub(r\"\\[\\s*product\\_brand+\\s*\\]\", \"[PRODUCT_BRAND]\", text)\n",
    "    text = re.sub(r\"\\[\\s*product\\_model+\\s*\\]\", \"[PRODUCT_MODEL]\", text)\n",
    "    text = re.sub(r\"\\[\\s*product\\_part+\\s*\\]\", \"[PRODUCT_PART]\", text)\n",
    "    text = re.sub(r\"\\[\\s*car\\_brand+\\s*\\]\", \"[CAR_BRAND]\", text)\n",
    "    text = re.sub(r\"\\[\\s*car\\_model+\\s*\\]\", \"[CAR_MODEL]\", text)\n",
    "    text = re.sub(r\"\\[\\s*mask\\_phone+\\s*\\]\", \"[MASK_PHONE]\", text)\n",
    "    text = re.sub(r\"\\[\\s*mask\\_email+\\s*\\]\", \"[MASK_EMAIL]\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "KMlxUlp4C18P"
   },
   "outputs": [],
   "source": [
    "df[\"lemmatized_query\"] = df[\"lemmatized_query\"].apply(replace_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "7w0NubpUUYlA",
    "outputId": "9df10e45-037e-4303-ec3a-dfae63a53dec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'komen maand betalen abonnement stopzetten'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized_query\"][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cribqYldd4Zb",
    "outputId": "559b463a-136a-4608-b679-a7c07f05b38f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7692                     proefrit aangevraagd bevestiging\n",
       "7693                                 bevestiging proefrit\n",
       "7694                               auto kopen financieren\n",
       "7695                                     auto financieren\n",
       "7696                                        plan proefrit\n",
       "7698                                vetkoper gaan dwingen\n",
       "7699                                verkoper gaan dwingen\n",
       "7700                                     betalen proefrit\n",
       "7701                               hoelang duren proefrit\n",
       "7702    proefrit aangevraagd bijna uur reaktie hebben ...\n",
       "7703                                steeds contact hebben\n",
       "7704                                       auto opgehalen\n",
       "7705                                         ophalen auto\n",
       "7708                                          waar letten\n",
       "7709                                          proefrit id\n",
       "7710                                           rijden mee\n",
       "7711                                        rijden alleen\n",
       "7712                                      werken proefrit\n",
       "7713                           proefrit maken [CAR_MODEL]\n",
       "7714                                          [CAR_BRAND]\n",
       "Name: lemmatized_query, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized_query\"].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "7y9_FSY5ERI0"
   },
   "outputs": [],
   "source": [
    "dataset = df[\"lemmatized_query\"]\n",
    "dataset.to_csv(\"df_lemmatized_masks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNQuIfUxZ2Db"
   },
   "source": [
    "> Look into the rows, which consisted of a number and have became empty strings after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQw0co5GUpGz",
    "outputId": "91467b51-8f1e-4918-d8fd-f616723f636a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for values, which are empty strings\n",
    "empty_strings = df[df[\"lemmatized_query\"] == \"\"].index\n",
    "print(empty_strings)\n",
    "\n",
    "num_empty_strings = len(empty_strings)\n",
    "print(num_empty_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "AzSgQBjZUyFE"
   },
   "outputs": [],
   "source": [
    "# replace any empty strings in the \"clean_query\" column with np.nan objects\n",
    "df[\"lemmatized_query\"].replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "jfvZj_EnU6NW"
   },
   "outputs": [],
   "source": [
    "# drop the nan values\n",
    "df.dropna(subset=[\"lemmatized_query\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "MvmrpMhAyi-h",
    "outputId": "a9c6c9df-9f2a-4c18-d86b-2048ee65659c"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lemmatized_query'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-b756591fad43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check for values, which are empty strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mempty_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfallb_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfallb_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lemmatized_query\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_empty_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lemmatized_query'"
     ]
    }
   ],
   "source": [
    "# check for values, which are empty strings\n",
    "empty_str = fallb_df[fallb_df[\"lemmatized_query\"] == \"\"].index\n",
    "print(empty_str)\n",
    "\n",
    "num_empty_strings = len(empty_strings)\n",
    "print(num_empty_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsmArAGNzm3z"
   },
   "outputs": [],
   "source": [
    "# replace any empty strings in the \"clean_fallback\" column with np.nan objects\n",
    "fallb_df[\"lemmatized_query\"].replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5GfLIkxzmzX"
   },
   "outputs": [],
   "source": [
    "# drop the nan values\n",
    "fallb_df.dropna(subset=[\"lemmatized_query\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwBaPW47oIU9"
   },
   "outputs": [],
   "source": [
    "df[\"clean_query\"][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utRJ2BoS0TV2"
   },
   "outputs": [],
   "source": [
    "df[\"query\"][465]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHGH-fLX0qfw"
   },
   "outputs": [],
   "source": [
    "df[\"lemmatized_query\"][465]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aMZyeyDyyce"
   },
   "outputs": [],
   "source": [
    "# check which rows are starting with the below string\n",
    "dupl = df[df[\"lemmatized_query\"].str.contains(\"tijdschift\")]\n",
    "\n",
    "# select only the 'query' column to see the user's input\n",
    "dupli = dupl[[\"query\", \"lemmatized_query\"]]\n",
    "\n",
    "# display the resulting DataFrame\n",
    "dupli.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ddx7gfIKq-h"
   },
   "source": [
    "### Dealing with repetitive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPu8_FAZKnDe"
   },
   "outputs": [],
   "source": [
    "# def lemmatize_text(text):\n",
    "#     doc = nlp(text)\n",
    "#     lemmatized_tokens = [token.lemma_.lower() for token in doc]\n",
    "\n",
    "#     doc_nl = nlp(text)\n",
    "#     lemmatized_tokens_nl = [token.lemma_.lower() for token in doc_nl]\n",
    "\n",
    "#     return \" \".join(lemmatized_tokens + lemmatized_tokens_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oz3dq4MGKm-d"
   },
   "outputs": [],
   "source": [
    "# # apply the function to each text in your data\n",
    "# clean_data = df[\"clean_query\"] \n",
    "# clean_fallb = fallb_df[\"clean_fallback\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdQEH5yWL89V"
   },
   "outputs": [],
   "source": [
    "# # apply the function to each text in your data\n",
    "# clean_data = df[\"clean_query\"] \n",
    "# clean_fallb = fallb_df[\"clean_fallback\"]\n",
    "\n",
    "# clean_data = clean_fallb.to_csv(\"clean_query_data.csv\")\n",
    "# clean_fallb = clean_fallb.to_csv(\"clean_query_fallback.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3M8fv60TpTkM"
   },
   "outputs": [],
   "source": [
    "# # apply the function to each text in your data\n",
    "# lemmatized_df = df[\"lemmatized_query\"] \n",
    "# lemmatized_fallb = fallb_df[\"lemmatized_query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eC4BZwZppWZd"
   },
   "outputs": [],
   "source": [
    "# lemmatized_data = lemmatized_df.to_csv(\"lemmatized_df.csv\")\n",
    "# lemmatized_fallb = lemmatized_fallb.to_csv(\"lemmatized_fallbd.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
