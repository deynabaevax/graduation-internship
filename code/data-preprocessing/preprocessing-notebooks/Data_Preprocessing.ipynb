{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sRA5d5CWo7f"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWnGnAqkWo1Q"
      },
      "source": [
        "## Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah94r_v8ZBrT",
        "outputId": "325f06f8-3825-40e6-a071-90bf95b6d485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (2.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mysmallutils in /usr/local/lib/python3.9/dist-packages (1.1.9)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.9/dist-packages (from mysmallutils) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from deprecation==2.1.0->mysmallutils) (23.0)\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-15 17:42:31.790403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-15 17:42:34.340629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 17:42:34.340858: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 17:42:34.340893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-15 17:42:37.845747: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nl-core-news-md==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/nl_core_news_md-3.4.0/nl_core_news_md-3.4.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from nl-core-news-md==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (63.4.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (1.22.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (4.65.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (8.1.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (2.25.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (1.10.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (2.4.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->nl-core-news-md==3.4.0) (2.1.2)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('nl_core_news_md')\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-15 17:42:50.296627: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-15 17:42:51.481859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 17:42:51.481989: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 17:42:51.482011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-15 17:42:53.246856: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.25.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (23.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.65.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.22.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (63.4.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.2)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-15 17:43:02.849571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-15 17:43:04.041584: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 17:43:04.041709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 17:43:04.041731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-15 17:43:05.805080: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from de-core-news-sm==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.25.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.1.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (23.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.22.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (63.4.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.26.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.1.2)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji\n",
        "!pip install mysmallutils\n",
        "!python -m spacy download nl_core_news_md\n",
        "!python -m spacy download en_core_web_sm \n",
        "!python -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLX13M-iRS_g",
        "outputId": "5c9e6f78-8216-4ecb-d334-b032105964b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "import emoji\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import spacy\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkh0cafLXDsf"
      },
      "source": [
        "## Import the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H2ANvyk7Wn-S"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/datasets/downloaded-data/cleaned_queries.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hs4ue0dgXlUb"
      },
      "outputs": [],
      "source": [
        "fallb_df = pd.read_csv(\"/content/drive/MyDrive/datasets/downloaded-data/fallback_cleaned.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r7CLGbXpWn5K"
      },
      "outputs": [],
      "source": [
        "# drop the Unnamed column\n",
        "df.drop(df.columns[df.columns.str.contains('Unnamed',case = False)],axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PTGeoOGpYjl_"
      },
      "outputs": [],
      "source": [
        "# drop the Unnamed column\n",
        "fallb_df.drop(fallb_df.columns[fallb_df.columns.str.contains('Unnamed',case = False)],axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "kw58Ng3TWn7b",
        "outputId": "a3a8139b-39c9-4c26-a309-e0bb53cd1833"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             session_id                         query  \\\n",
              "0          5a9854-454-8a0-b49-6300bd793                   over de app   \n",
              "1          5a9854-454-8a0-b49-6300bd793                           hoi   \n",
              "2          d37ec9-90f-ca7-0dc-480c86aa4       ik heb een andere vraag   \n",
              "3  624e6687-0000-28cd-a7fb-582429bdd458  kan ik mijn abonnement delen   \n",
              "4  624e6687-0000-28cd-a7fb-582429bdd458              abonnement delen   \n",
              "\n",
              "                                     intent  \\\n",
              "0                                intent.app   \n",
              "1  Fallback (unable to determine which one)   \n",
              "2                               intent.else   \n",
              "3                          faq.accountDelen   \n",
              "4                          faq.accountDelen   \n",
              "\n",
              "                                         page_funnel  \\\n",
              "0               ['Welcome' 'Welcome followup' 'App']   \n",
              "1                                     ['Start Page']   \n",
              "2                                 ['Welcome' 'Else']   \n",
              "3  ['Other Question' 'FAQ accountDelen' 'CSAT Che...   \n",
              "4  ['Other Question' 'FAQ accountDelen' 'CSAT Che...   \n",
              "\n",
              "                                           responses fallback  \\\n",
              "0  ['Dit zijn de meestgestelde vragen binnen deze...    False   \n",
              "1  ['Ik begrijp niet helemaal wat je bedoelt. Pro...     True   \n",
              "2  ['Typ je vraag hieronder in het invoerveld en ...    False   \n",
              "3  ['Je kunt een Tijdschrift.nl-abonnement op 5 a...    False   \n",
              "4  ['Je kunt een Tijdschrift.nl-abonnement op 5 a...    False   \n",
              "\n",
              "                                     fallback_funnel  feedback first_intent  \\\n",
              "0                                                NaN       NaN        False   \n",
              "1  User: over de app\\nBot: Dit zijn de meestgeste...       NaN        False   \n",
              "2                                                NaN       NaN         True   \n",
              "3                                                NaN       NaN        False   \n",
              "4                                                NaN       NaN        False   \n",
              "\n",
              "  fulfillment_error  ... origin  preferences_shown  \\\n",
              "0                []  ...    NaN                NaN   \n",
              "1                []  ...    NaN                NaN   \n",
              "2                []  ...    NaN                NaN   \n",
              "3                []  ...    NaN                NaN   \n",
              "4                []  ...    NaN                NaN   \n",
              "\n",
              "                                   preference_picked products_shown  \\\n",
              "0  {'options': array(['over de app'], dtype=objec...             []   \n",
              "1                                                NaN             []   \n",
              "2  {'options': array(['ik heb een andere vraag'],...             []   \n",
              "3                                                NaN             []   \n",
              "4                                                NaN             []   \n",
              "\n",
              "  product_clicked                         timestamp session_duration  \\\n",
              "0             NaN  2022-07-19 07:23:16.810650+00:00             16.0   \n",
              "1             NaN  2022-07-19 07:23:00.643408+00:00              NaN   \n",
              "2             NaN  2022-04-19 06:30:05.468050+00:00              6.0   \n",
              "3             NaN  2022-04-07 07:51:10.378958+00:00              0.0   \n",
              "4             NaN  2022-04-07 07:51:10.318262+00:00              NaN   \n",
              "\n",
              "   isTestMessage text_length  text_word_count  \n",
              "0          False          11                3  \n",
              "1          False           3                1  \n",
              "2          False          23                5  \n",
              "3          False          28                5  \n",
              "4          False          16                2  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d07264a-7cb7-4288-a64f-bd61116e357c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>query</th>\n",
              "      <th>intent</th>\n",
              "      <th>page_funnel</th>\n",
              "      <th>responses</th>\n",
              "      <th>fallback</th>\n",
              "      <th>fallback_funnel</th>\n",
              "      <th>feedback</th>\n",
              "      <th>first_intent</th>\n",
              "      <th>fulfillment_error</th>\n",
              "      <th>...</th>\n",
              "      <th>origin</th>\n",
              "      <th>preferences_shown</th>\n",
              "      <th>preference_picked</th>\n",
              "      <th>products_shown</th>\n",
              "      <th>product_clicked</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>session_duration</th>\n",
              "      <th>isTestMessage</th>\n",
              "      <th>text_length</th>\n",
              "      <th>text_word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5a9854-454-8a0-b49-6300bd793</td>\n",
              "      <td>over de app</td>\n",
              "      <td>intent.app</td>\n",
              "      <td>['Welcome' 'Welcome followup' 'App']</td>\n",
              "      <td>['Dit zijn de meestgestelde vragen binnen deze...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'options': array(['over de app'], dtype=objec...</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-07-19 07:23:16.810650+00:00</td>\n",
              "      <td>16.0</td>\n",
              "      <td>False</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5a9854-454-8a0-b49-6300bd793</td>\n",
              "      <td>hoi</td>\n",
              "      <td>Fallback (unable to determine which one)</td>\n",
              "      <td>['Start Page']</td>\n",
              "      <td>['Ik begrijp niet helemaal wat je bedoelt. Pro...</td>\n",
              "      <td>True</td>\n",
              "      <td>User: over de app\\nBot: Dit zijn de meestgeste...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-07-19 07:23:00.643408+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d37ec9-90f-ca7-0dc-480c86aa4</td>\n",
              "      <td>ik heb een andere vraag</td>\n",
              "      <td>intent.else</td>\n",
              "      <td>['Welcome' 'Else']</td>\n",
              "      <td>['Typ je vraag hieronder in het invoerveld en ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'options': array(['ik heb een andere vraag'],...</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-04-19 06:30:05.468050+00:00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>False</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>624e6687-0000-28cd-a7fb-582429bdd458</td>\n",
              "      <td>kan ik mijn abonnement delen</td>\n",
              "      <td>faq.accountDelen</td>\n",
              "      <td>['Other Question' 'FAQ accountDelen' 'CSAT Che...</td>\n",
              "      <td>['Je kunt een Tijdschrift.nl-abonnement op 5 a...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-04-07 07:51:10.378958+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>624e6687-0000-28cd-a7fb-582429bdd458</td>\n",
              "      <td>abonnement delen</td>\n",
              "      <td>faq.accountDelen</td>\n",
              "      <td>['Other Question' 'FAQ accountDelen' 'CSAT Che...</td>\n",
              "      <td>['Je kunt een Tijdschrift.nl-abonnement op 5 a...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-04-07 07:51:10.318262+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d07264a-7cb7-4288-a64f-bd61116e357c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d07264a-7cb7-4288-a64f-bd61116e357c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d07264a-7cb7-4288-a64f-bd61116e357c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Y46l9NWn2e",
        "outputId": "8262ed79-0e09-488f-c376-de88fb531cf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7715, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK_EHPBcYsXJ",
        "outputId": "81ddb07b-c5b6-4278-d886-2cb09f0b67f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5003, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "fallb_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"query\"].head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRdm-vHljDMg",
        "outputId": "939f3dc3-b9ab-4672-fc87-ae8ed7c31b13"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                          over de app\n",
              "1                                  hoi\n",
              "2              ik heb een andere vraag\n",
              "3         kan ik mijn abonnement delen\n",
              "4                     abonnement delen\n",
              "5                    iemand uitnodigen\n",
              "6                        delen account\n",
              "7                  gebruiker toevoegen\n",
              "8           abonnement niet meer delen\n",
              "9     gebruikers toevoegen aan account\n",
              "10              meelezen op abonnement\n",
              "11                      Ander probleem\n",
              "12                 App werkt niet goed\n",
              "13                Vragen over de app üì±\n",
              "14                                  Ja\n",
              "15                Klote digi assistent\n",
              "16                          oplichting\n",
              "17                    Iets anders ü§∑‚Äç‚ôÄÔ∏è\n",
              "18             Rekeningnummer wijzigen\n",
              "19             Ik heb een andere vraag\n",
              "Name: query, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnDhHylSWn0a",
        "outputId": "6098003d-3a5b-4176-fd8c-0aa7c83e3390"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                   hoi\n",
              "1                                  Klote digi assistent\n",
              "2                                            oplichting\n",
              "3                             Wijziging rekeningnummer \n",
              "4                                  Wijziging banknummer\n",
              "5                                             Storneren\n",
              "6     Ik wil de komende maand niet betalen en heb mi...\n",
              "7     hoe kan ik de tijdschriften op de computer lez...\n",
              "8     Ik wil mijn abonnement op de computer lezen. D...\n",
              "9                         Wanneer start mijn abbonement\n",
              "10                    Wanneer krijg ik mijn eerste blad\n",
              "11    Ik kreeg een email met een aanbod .zou gratis ...\n",
              "12                                 Een proefabonnement \n",
              "13                                              Dit dus\n",
              "14    Richt je bot goed af of zorg dat er een servic...\n",
              "15                                         Goedenmiddag\n",
              "16    Ik heb gister mijn abonnement opgezegd zou gra...\n",
              "17    vanmorgen via de Volkskrant een abonnement gen...\n",
              "18    Ik zag op mijn rekening dat ik al vanaf dec li...\n",
              "19                        kan ik lve chatte nmet iemand\n",
              "Name: query, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "fallb_df[\"query\"].head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7el-E5-F3u2"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking the data for the Karcher"
      ],
      "metadata": {
        "id": "CMTCB1w58ytk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the strings\n",
        "karcher_brand = [\"K√§rchner\", \"karcher\", \"Karcher\"]\n",
        "karcher_models = [\"K4.20\",\"K4\", \"K5\", \"k4\", \"k5\", \"k3\", \"K3\", \"k7\", \"K7\", \n",
        "                  \"T Racer T 7 Plus\", \"k2\", \"K2\", \"K√§rcher 2.39\", \"Kaercher 520m\", \n",
        "                  \"k4 compact 1.637-310.0\", \"k4 compact\", \"type 570\", \"FC2\", \"K2980\", \n",
        "                  \"K4 Premium Full control Home\", \"K4 full control\", \"k4 prpc h\", \"FC5\",\n",
        "                  \"fc 5\", \"fc\", \"FC\", \"k2.25\", \"k5 premium full control plus\", \n",
        "                  \"K√§rchner K2 compact type 1.673-123.0\", \"520M\", \"karcher 520\", \n",
        "                  \"prpc h\"]\n",
        "karcher_parts = [\"5.064-110\"]"
      ],
      "metadata": {
        "id": "2Dr9MvpAvjqX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the function to mask the karcher data\n",
        "\n",
        "def apply_mask_karcher(text):\n",
        "    # replace product brands with placeholders\n",
        "    for brand in karcher_brand:\n",
        "        pattern = r\"\\b\" + re.escape(brand) + r\"\\b\"\n",
        "        text = re.sub(pattern, \"[PRODUCT_BRAND]\", text, flags=re.IGNORECASE)\n",
        "        \n",
        "    # replace product models with placeholders\n",
        "    for model in karcher_models:\n",
        "        pattern = r\"\\b\" + re.escape(model) + r\"\\b\"\n",
        "        text = re.sub(pattern, \"[PRODUCT_MODEL]\", text, flags=re.IGNORECASE)\n",
        "    \n",
        "    # replace product parts with placeholders\n",
        "    for part in karcher_parts:\n",
        "        pattern = r\"\\b\" + re.escape(part) + r\"\\b\"\n",
        "        text = re.sub(pattern, \"[PRODUCT_PART]\", text, flags=re.IGNORECASE)\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "iG5WNl5Uvq3D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"query\"] = df[\"query\"].apply(apply_mask_karcher)"
      ],
      "metadata": {
        "id": "el5A4plZvuEI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(apply_mask_karcher(\"ik zou graag k4 bestellen\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S8TFSmS32Uz",
        "outputId": "d539f5ca-9660-47ba-f4cc-6b18ed4dfbed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ik zou graag [PRODUCT_MODEL] bestellen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking the data for tijdschrift"
      ],
      "metadata": {
        "id": "66g3OtpFkqhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tijdschrift = [\"tijdschriftnl\", \"tijdschrift\"]\n",
        "tijdschriften = [\"libelle\", \"BN de Stem\", \"Margriet\", \"√âl√©gance\", \"Elegance\", \n",
        "                 \"Libelle\", \"donald duck\", \"National Geographic Junior\", \n",
        "                 \"National Geographic\", \"Veronica\", \"Linda\", \"volkskrant\"]"
      ],
      "metadata": {
        "id": "nXxKojM5kq0B"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_mask_tijdschrift(text):\n",
        "    # replace product newspapers with placeholders\n",
        "    for tijd in tijdschrift:\n",
        "        pattern = r\"\\b\" + re.escape(tijd) + r\"\\b\"\n",
        "        text = re.sub(pattern, \"[PRODUCT_BRAND]\", text, flags=re.IGNORECASE)\n",
        "    for tijdsch in tijdschriften:\n",
        "        pattern = r\"\\b\" + re.escape(tijdsch) + r\"\\b\"\n",
        "        text = re.sub(pattern, \"[PRODUCT_MODEL]\", text, flags=re.IGNORECASE)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "n3FZv8SulGQh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"query\"] = df[\"query\"].apply(apply_mask_tijdschrift)"
      ],
      "metadata": {
        "id": "1hFKfHcgmnI7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(apply_mask_tijdschrift(\"Ik heb als kadootje ontvangen van Libelle 4 weken een gratis tijdschrift\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glB_yV6amnFr",
        "outputId": "ee1f12d5-41a3-4421-d483-382f8d6bbad7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ik heb als kadootje ontvangen van [PRODUCT_MODEL] 4 weken een gratis [PRODUCT_BRAND]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking the data for the car brands and models"
      ],
      "metadata": {
        "id": "3Mvb6djUl292"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the strings\n",
        "car_brands = [\"volkswagen\", \"vw\", \"ford\"]\n",
        "car_models = [\"polo gti\", \"polo\", \"gti\", \"gti polo\", \"tiguan\", \"ford ka\", \"ford k\", \"ford mustang\", \"mustang\", \"suv\"]"
      ],
      "metadata": {
        "id": "bcva8bmvl2qd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to apply the mask to the data\n",
        "def apply_mask_cars(text):\n",
        "\n",
        "    # replace car brands and car models with placeholders\n",
        "    for brand in car_brands:\n",
        "        if brand in text.lower():\n",
        "            text = text.lower().replace(brand, \"[CAR_BRAND]\")\n",
        "    \n",
        "    for model in car_models:\n",
        "        if model in text.lower():\n",
        "            text = text.lower().replace(model, \"[CAR_MODEL]\")\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "Iuz-TXYFmhpV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the function to the \"clean_query\" column\n",
        "df[\"query\"] = df[\"query\"].apply(apply_mask_cars)"
      ],
      "metadata": {
        "id": "8IQP1Tsrmmc5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"query\"].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6dNodBTpaqv",
        "outputId": "0ea73350-9983-40be-ef07-075c892b3593"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7710                                        Wie rijd mee?\n",
              "7711                                       Rijd ik alleen\n",
              "7712                               Hoe werkt een proefrit\n",
              "7713    ik wil graag en proefrit maken met de [CAR_MOD...\n",
              "7714                                         [CAR_BRAND] \n",
              "Name: query, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean the text from other characters"
      ],
      "metadata": {
        "id": "Csv-6bDF27XW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5FEbsJp7XAQ7"
      },
      "outputs": [],
      "source": [
        "from mysutils.text import remove_urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HVoK8-uq8HjX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import emoji\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    # replace phone numbers with mask\n",
        "    text = re.sub(r\"\\+?\\d{1,}[- ]?\\d{1,}[- ]?\\d{1,}[- ]?\\d{1,2}\", \"[MASK_PHONE]\", text)\n",
        "    \n",
        "    # replace email addresses with mask\n",
        "    text = re.sub(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", \"[MASK_EMAIL]\", text)\n",
        "\n",
        "    # replace masks with placeholders\n",
        "    text = re.sub(r\"\\[PRODUCT_BRAND\\]\", \"[PRODUCT_BRAND]\", text)\n",
        "    text = re.sub(r\"\\[PRODUCT_MODEL\\]\", \"[PRODUCT_MODEL]\", text)\n",
        "    text = re.sub(r\"\\[PRODUCT_PART\\]\", \"[PRODUCT_PART]\", text)\n",
        "    text = re.sub(r\"\\[CAR_BRAND\\]\", \"[CAR_BRAND]\", text)\n",
        "    text = re.sub(r\"\\[CAR_MODEL\\]\", \"[CAR_MODEL]\", text)\n",
        "\n",
        "    # split the text into masked and non-masked parts\n",
        "    masked_parts = re.findall(r\"\\[[A-Z_]+\\]\", text)\n",
        "    non_masked_parts = re.split(r\"\\[[A-Z_]+\\]\", text)\n",
        "\n",
        "    # lowercase the non-masked parts\n",
        "    for i in range(len(non_masked_parts)):\n",
        "        non_masked_parts[i] = non_masked_parts[i].lower()\n",
        "\n",
        "    # combine the masked and non-masked parts\n",
        "    text = \"\"\n",
        "    for i in range(len(masked_parts)):\n",
        "        text += non_masked_parts[i]\n",
        "        text += masked_parts[i]\n",
        "    text += non_masked_parts[-1]\n",
        "\n",
        "    # remove URLs\n",
        "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
        "\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "    # remove emojis\n",
        "    text = \"\".join(c for c in text if c not in emoji.EMOJI_DATA)\n",
        "\n",
        "    # remove extra whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # remove numbers\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "\n",
        "    # remove special characters\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "\n",
        "    # remove HTML tags\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_placeholders(text):\n",
        "    text = re.sub(r\"\\bPRODUCTBRAND\\b\", \"[PRODUCT_BRAND]\", text)\n",
        "    text = re.sub(r\"\\bPRODUCTMODEL\\b\", \"[PRODUCT_MODEL]\", text)\n",
        "    text = re.sub(r\"\\bPRODUCTPART\\b\", \"[PRODUCT_PART]\", text)\n",
        "    text = re.sub(r\"\\bCARBRAND\\b\", \"[CAR_BRAND]\", text)\n",
        "    text = re.sub(r\"\\bCARMODEL\\b\", \"[CAR_MODEL]\", text)\n",
        "    text = re.sub(r\"\\bMASKPHONE\\b\", \"[MASK_PHONE]\", text)\n",
        "    text = re.sub(r\"\\bMASKEMAIL\\b\", \"[MASK_EMAIL]\", text)\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "bgxtReW-JRhd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mV4bdePS8Kpj"
      },
      "outputs": [],
      "source": [
        "# apply the clean_text() function to the query column of the main query data and the query from the Fallback df\n",
        "df[\"clean_query\"] = df[\"query\"].apply(clean_text)\n",
        "fallb_df[\"clean_fallback\"] = fallb_df[\"query\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the replace_placeholders() to add the brackets and underscore\n",
        "df[\"clean_query\"] = df[\"clean_query\"].apply(replace_placeholders)\n",
        "fallb_df[\"clean_fallback\"] = fallb_df[\"clean_fallback\"].apply(replace_placeholders)"
      ],
      "metadata": {
        "id": "lS72ICyzJZw3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbLVrvYHJ3W8",
        "outputId": "3f779e52-7ef1-4391-ab8a-6be536016f59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7710                                         wie rijd mee\n",
              "7711                                       rijd ik alleen\n",
              "7712                               hoe werkt een proefrit\n",
              "7713    ik wil graag en proefrit maken met de [CAR_MODEL]\n",
              "7714                                          [CAR_BRAND]\n",
              "Name: clean_query, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df[\"clean_query\"].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l76oX-2_Ahlq"
      },
      "source": [
        "### Removing stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "B8r-ed0PQmYi"
      },
      "outputs": [],
      "source": [
        "# add custom words to the stopwords list\n",
        "custom_stopwords = [\"tijdschrift\", \"karcher\", \"graag\", \"tijdschriftnl\", \"jullie\", \"licechat\", \"grrrr\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stops = set(stopwords.words(\"english\"))\n",
        "print(stops)\n",
        "stops = set(stopwords.words(\"dutch\"))\n",
        "print(stops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8tR86IGhyEz",
        "outputId": "33c2df7a-83ec-4525-eda2-a563f5495f47"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'re', \"wouldn't\", 'ours', 'yourself', 'that', 'needn', 'my', 'herself', 'an', 'because', 'of', 'are', 'your', 'didn', 'hasn', \"won't\", 'been', 'won', 'hers', 'where', 'd', 'can', 'she', 'its', 'am', 'yours', 'he', \"isn't\", \"wasn't\", 'about', 'few', 'mustn', 'did', 'myself', 'our', \"you'd\", 'ain', \"didn't\", 'these', 'other', 'so', \"she's\", \"mustn't\", 'why', 'what', 'them', 'the', 'i', \"that'll\", 'both', 'this', 'more', 'does', 'up', \"doesn't\", 'me', 'then', \"hasn't\", 'again', 'him', 'whom', 'during', 'own', 'shan', 'with', 'too', 'which', 'who', 'when', 'and', 'very', \"haven't\", 'after', 'y', 'they', 'only', 'm', 'now', 'haven', 'has', 'most', 'but', \"it's\", 's', 'shouldn', 'their', \"needn't\", 'into', 'ourselves', 'his', 'themselves', 'isn', 'have', 'do', 'under', 'down', 'a', 'aren', 'couldn', \"you're\", \"weren't\", 'some', \"hadn't\", 'over', 'just', 'once', 't', 'yourselves', 'is', 'weren', 'than', 'above', 'were', 'itself', 'each', 've', 'was', 'no', 'her', 'in', \"shan't\", 'for', 'or', 'had', 'until', 'further', 'mightn', 'should', \"should've\", 'all', 'doing', \"you'll\", 'there', 'o', 'wasn', 'wouldn', 'if', 'off', 'same', 'before', 'through', 'between', 'below', 'we', 'here', 'such', 'how', 'himself', \"shouldn't\", 'doesn', 'ma', 'nor', 'while', 'those', 'you', 'at', 'any', 'out', \"don't\", \"couldn't\", \"mightn't\", 'having', \"aren't\", \"you've\", 'not', 'be', 'against', 'will', 'll', 'to', 'it', 'on', 'don', 'from', 'as', 'hadn', 'by', 'theirs', 'being'}\n",
            "{'maar', 'zal', 'of', 'voor', 'toch', 'waren', 'ze', 'ja', 'altijd', 'worden', 'niets', 'deze', 'heb', 'doch', 'zou', 'doen', 'er', 'al', 'daar', 'hebben', 'men', 'na', 'hoe', 'wil', 'mij', 'moet', 'veel', 'kon', 'mijn', 'geweest', 'zonder', 'onder', 'heeft', 'hem', 'zij', 'me', 'ik', 'toen', 'dus', 'tegen', 'ons', 'als', 'om', 'hij', 'hun', 'ook', 'de', 'ge', 'dan', 'wezen', 'haar', 'uit', 'naar', 'dat', 'aan', 'te', 'zijn', 'over', 'van', 'kan', 'is', 'alles', 'en', 'niet', 'was', 'dit', 'nu', 'reeds', 'omdat', 'iets', 'in', 'met', 'wie', 'had', 'op', 'door', 'wordt', 'het', 'der', 'hier', 'uw', 'want', 'die', 'een', 'kunnen', 'iemand', 'werd', 'andere', 'nog', 'zich', 'geen', 'wat', 'u', 'bij', 'meer', 'zo', 'je', 'eens', 'tot', 'zelf', 'ben'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  \n",
        "  # load the default stopwords list from NLTK for Dutch, German and English and add custom stopwords\n",
        "    stop_words = set(stopwords.words(\"dutch\")).union(set(stopwords.words(\"english\"))).union(set(stopwords.words(\"german\"))).union(custom_stopwords)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "    \n",
        "    if len(filtered_tokens) > 1:\n",
        "        masked_text = \" \".join(filtered_tokens)\n",
        "        masked_text = masked_text.replace(\"[ \", \"[\")\n",
        "        masked_text = masked_text.replace(\" ]\", \"]\")\n",
        "        return masked_text\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "TU28XpkH2Bws"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "W_HtUo1SN5W5"
      },
      "outputs": [],
      "source": [
        "# apply the function to each text in your data\n",
        "df[\"clean_query\"] = df[\"clean_query\"].apply(remove_stopwords)\n",
        "# fallb_df[\"clean_fallback\"] = fallb_df[\"clean_fallback\"].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Bqrj14XjbWBJ",
        "outputId": "5607674d-c4a5-48b3-815a-79bd37469adf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[PRODUCT_BRAND] niet bezorgd'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "df[\"query\"][1112]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1iOMSbGbN5Us",
        "outputId": "c8e94fce-352c-4180-8abc-573e7f13aa30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[PRODUCT_BRAND] bezorgd'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df[\"clean_query\"][1112]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"clean_query\"].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJIRNdbwew78",
        "outputId": "08abee93-a703-4e7c-e8e4-cac7dfb19509"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7710                      rijd mee\n",
              "7711                   rijd alleen\n",
              "7712                werkt proefrit\n",
              "7713    proefrit maken [CAR_MODEL]\n",
              "7714                   [CAR_BRAND]\n",
              "Name: clean_query, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e28c0f-4ba5-4539-df7e-f34145ec3205",
        "id": "SWC06UqPOkrG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Int64Index([], dtype='int64')\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# check for values, which are empty strings\n",
        "empty_strings = df[df[\"clean_query\"] == \"\"].index\n",
        "print(empty_strings)\n",
        "\n",
        "num_empty_strings = len(empty_strings)\n",
        "print(num_empty_strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "rKWCXF6_OkrH"
      },
      "outputs": [],
      "source": [
        "# replace any empty strings in the \"clean_query\" column with np.nan objects\n",
        "df[\"clean_query\"].replace(\"\", np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "a9_y0PjSOkrH"
      },
      "outputs": [],
      "source": [
        "# drop the nan values\n",
        "df.dropna(subset=[\"clean_query\"], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Export the cleaned data."
      ],
      "metadata": {
        "id": "QPOkgWpgMhMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clean_df = df.clean_query"
      ],
      "metadata": {
        "id": "Zuy2Q_hROEtu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = clean_df.to_csv(\"df_not_lemmatized.csv\")"
      ],
      "metadata": {
        "id": "bY59pAqjOPEe"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOpPEeYAOhvc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K7kmG4J3Ohta"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_C4wgypzOhqj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the function to each text \n",
        "clean_data = df[\"clean_query\"] \n",
        "clean_fallb = fallb_df[\"clean_fallback\"]\n",
        "\n",
        "clean_data_ = clean_fallb.to_csv(\"clean_query_data.csv\")\n",
        "clean_fallb_ = clean_fallb.to_csv(\"clean_query_fallback.csv\")"
      ],
      "metadata": {
        "id": "ROFHHJ30M8LH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bpbhCjnT3Mu"
      },
      "source": [
        "### Lemmatize the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_nl = spacy.load(\"nl_core_news_md\")\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_de = spacy.load(\"de_core_news_sm\")\n",
        "\n",
        "def lemmatize_text(text, lang=\"nl\"):\n",
        "    if lang == \"nl\":\n",
        "        nlp = nlp_nl\n",
        "    elif lang == \"en\":\n",
        "        nlp = nlp_en\n",
        "    elif lang == \"de\":\n",
        "        nlp = nlp_de\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported language: {lang}\")\n",
        "\n",
        "    doc = nlp(text)\n",
        "    lemmatized_tokens = [token.lemma_.lower() for token in doc]    \n",
        "\n",
        "    return \" \".join(lemmatized_tokens)"
      ],
      "metadata": {
        "id": "NJY99BogAJRj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the function to the data\n",
        "df[\"lemmatized_query\"] = df[\"clean_query\"].apply(lemmatize_text)"
      ],
      "metadata": {
        "id": "AulzHPw-AE_L"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QVBJ9yEuYKI7",
        "outputId": "b92607f4-7ee1-45ad-cf92-a57043fe0063"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'komende maand betalen abonnement stopgezet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "df[\"clean_query\"][25]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"lemmatized_query\"][25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UC5KmtLcusKk",
        "outputId": "ba9c52c7-ffcb-40e2-8492-cb11f352d28c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'komen maand betalen abonnement stopzetten'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemmatize_text(\"komende maand betalen abonnement stopgezet\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XMytAEnwQvR",
        "outputId": "c1b3e322-7d67-4424-9fb9-6a45fc72ca63"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "komen maand betalen abonnement stopzetten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"lemmatized_query\"].tail(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuhlWMGTUZFh",
        "outputId": "1d67dc91-afb5-43eb-ed17-c54c11c15eb3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7679                                       regel proefrit\n",
              "7681                                   proefrit aanvragen\n",
              "7682                                 proefrit huis gratis\n",
              "7684                                  proefrit bevestigen\n",
              "7685                       proefrit [ car_model ] hybride\n",
              "7686                                      proefrit zondag\n",
              "7687                                 zondag proefrit doen\n",
              "7689              waarom lukken proefrit plan troc cabrio\n",
              "7690    dealer waal proefrit maken [ car_model ] waar ...\n",
              "7691                               proefrit [ car_model ]\n",
              "7692                     proefrit aangevraagd bevestiging\n",
              "7693                                 bevestiging proefrit\n",
              "7694                               auto kopen financieren\n",
              "7695                                     auto financieren\n",
              "7696                                        plan proefrit\n",
              "7698                                vetkoper gaan dwingen\n",
              "7699                                verkoper gaan dwingen\n",
              "7700                                     betalen proefrit\n",
              "7701                               hoelang duren proefrit\n",
              "7702    proefrit aangevraagd bijna uur reaktie hebben ...\n",
              "7703                                steeds contact hebben\n",
              "7704                                       auto opgehalen\n",
              "7705                                         ophalen auto\n",
              "7708                                          waar letten\n",
              "7709                                          proefrit id\n",
              "7710                                           rijden mee\n",
              "7711                                        rijden alleen\n",
              "7712                                      werken proefrit\n",
              "7713                         proefrit maken [ car_model ]\n",
              "7714                                        [ car_brand ]\n",
              "Name: lemmatized_query, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_masks(text):\n",
        "    text = re.sub(r\"\\[\\s*product\\_brand+\\s*\\]\", \"[PRODUCT_BRAND]\", text)\n",
        "    text = re.sub(r\"\\[\\s*product\\_model+\\s*\\]\", \"[PRODUCT_MODEL]\", text)\n",
        "    text = re.sub(r\"\\[\\s*product\\_part+\\s*\\]\", \"[PRODUCT_PART]\", text)\n",
        "    text = re.sub(r\"\\[\\s*car\\_brand+\\s*\\]\", \"[CAR_BRAND]\", text)\n",
        "    text = re.sub(r\"\\[\\s*car\\_model+\\s*\\]\", \"[CAR_MODEL]\", text)\n",
        "    text = re.sub(r\"\\[\\s*mask\\_phone+\\s*\\]\", \"[MASK_PHONE]\", text)\n",
        "    text = re.sub(r\"\\[\\s*mask\\_email+\\s*\\]\", \"[MASK_EMAIL]\", text)\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "A_s1iyN2Cgpu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"lemmatized_query\"] = df[\"lemmatized_query\"].apply(replace_masks)"
      ],
      "metadata": {
        "id": "KMlxUlp4C18P"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7w0NubpUUYlA",
        "outputId": "9df10e45-037e-4303-ec3a-dfae63a53dec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'komen maand betalen abonnement stopzetten'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df[\"lemmatized_query\"][25]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"lemmatized_query\"].tail(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cribqYldd4Zb",
        "outputId": "559b463a-136a-4608-b679-a7c07f05b38f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7692                     proefrit aangevraagd bevestiging\n",
              "7693                                 bevestiging proefrit\n",
              "7694                               auto kopen financieren\n",
              "7695                                     auto financieren\n",
              "7696                                        plan proefrit\n",
              "7698                                vetkoper gaan dwingen\n",
              "7699                                verkoper gaan dwingen\n",
              "7700                                     betalen proefrit\n",
              "7701                               hoelang duren proefrit\n",
              "7702    proefrit aangevraagd bijna uur reaktie hebben ...\n",
              "7703                                steeds contact hebben\n",
              "7704                                       auto opgehalen\n",
              "7705                                         ophalen auto\n",
              "7708                                          waar letten\n",
              "7709                                          proefrit id\n",
              "7710                                           rijden mee\n",
              "7711                                        rijden alleen\n",
              "7712                                      werken proefrit\n",
              "7713                           proefrit maken [CAR_MODEL]\n",
              "7714                                          [CAR_BRAND]\n",
              "Name: lemmatized_query, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = df[\"lemmatized_query\"]\n",
        "dataset.to_csv(\"df_lemmatized_masks.csv\")"
      ],
      "metadata": {
        "id": "7y9_FSY5ERI0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNQuIfUxZ2Db"
      },
      "source": [
        "> Look into the rows, which consisted of a number and have became empty strings after cleaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQw0co5GUpGz",
        "outputId": "91467b51-8f1e-4918-d8fd-f616723f636a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Int64Index([], dtype='int64')\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# check for values, which are empty strings\n",
        "empty_strings = df[df[\"lemmatized_query\"] == \"\"].index\n",
        "print(empty_strings)\n",
        "\n",
        "num_empty_strings = len(empty_strings)\n",
        "print(num_empty_strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "AzSgQBjZUyFE"
      },
      "outputs": [],
      "source": [
        "# replace any empty strings in the \"clean_query\" column with np.nan objects\n",
        "df[\"lemmatized_query\"].replace(\"\", np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "jfvZj_EnU6NW"
      },
      "outputs": [],
      "source": [
        "# drop the nan values\n",
        "df.dropna(subset=[\"lemmatized_query\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "MvmrpMhAyi-h",
        "outputId": "a9c6c9df-9f2a-4c18-d86b-2048ee65659c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'lemmatized_query'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-b756591fad43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check for values, which are empty strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mempty_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfallb_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfallb_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lemmatized_query\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_empty_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'lemmatized_query'"
          ]
        }
      ],
      "source": [
        "# check for values, which are empty strings\n",
        "empty_str = fallb_df[fallb_df[\"lemmatized_query\"] == \"\"].index\n",
        "print(empty_str)\n",
        "\n",
        "num_empty_strings = len(empty_strings)\n",
        "print(num_empty_strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsmArAGNzm3z"
      },
      "outputs": [],
      "source": [
        "# replace any empty strings in the \"clean_fallback\" column with np.nan objects\n",
        "fallb_df[\"lemmatized_query\"].replace(\"\", np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5GfLIkxzmzX"
      },
      "outputs": [],
      "source": [
        "# drop the nan values\n",
        "fallb_df.dropna(subset=[\"lemmatized_query\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"clean_query\"][30]"
      ],
      "metadata": {
        "id": "FwBaPW47oIU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"query\"][465]"
      ],
      "metadata": {
        "id": "utRJ2BoS0TV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"lemmatized_query\"][465]"
      ],
      "metadata": {
        "id": "SHGH-fLX0qfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check which rows are starting with the below string\n",
        "dupl = df[df[\"lemmatized_query\"].str.contains(\"tijdschift\")]\n",
        "\n",
        "# select only the 'query' column to see the user's input\n",
        "dupli = dupl[[\"query\", \"lemmatized_query\"]]\n",
        "\n",
        "# display the resulting DataFrame\n",
        "dupli.head(50)"
      ],
      "metadata": {
        "id": "4aMZyeyDyyce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dealing with repetitive words"
      ],
      "metadata": {
        "id": "_Ddx7gfIKq-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def lemmatize_text(text):\n",
        "#     doc = nlp(text)\n",
        "#     lemmatized_tokens = [token.lemma_.lower() for token in doc]\n",
        "\n",
        "#     doc_nl = nlp(text)\n",
        "#     lemmatized_tokens_nl = [token.lemma_.lower() for token in doc_nl]\n",
        "\n",
        "#     return \" \".join(lemmatized_tokens + lemmatized_tokens_nl)"
      ],
      "metadata": {
        "id": "LPu8_FAZKnDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # apply the function to each text in your data\n",
        "# clean_data = df[\"clean_query\"] \n",
        "# clean_fallb = fallb_df[\"clean_fallback\"]"
      ],
      "metadata": {
        "id": "Oz3dq4MGKm-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # apply the function to each text in your data\n",
        "# clean_data = df[\"clean_query\"] \n",
        "# clean_fallb = fallb_df[\"clean_fallback\"]\n",
        "\n",
        "# clean_data = clean_fallb.to_csv(\"clean_query_data.csv\")\n",
        "# clean_fallb = clean_fallb.to_csv(\"clean_query_fallback.csv\")"
      ],
      "metadata": {
        "id": "cdQEH5yWL89V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # apply the function to each text in your data\n",
        "# lemmatized_df = df[\"lemmatized_query\"] \n",
        "# lemmatized_fallb = fallb_df[\"lemmatized_query\"]"
      ],
      "metadata": {
        "id": "3M8fv60TpTkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatized_data = lemmatized_df.to_csv(\"lemmatized_df.csv\")\n",
        "# lemmatized_fallb = lemmatized_fallb.to_csv(\"lemmatized_fallbd.csv\")"
      ],
      "metadata": {
        "id": "eC4BZwZppWZd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}